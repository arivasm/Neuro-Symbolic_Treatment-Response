{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36ad9f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.models import predict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import math\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "\n",
    "def select_graph(n):\n",
    "    # th_lowEffect = 32.59991399904  # means 308\n",
    "    # th_effective = 67.4008600096  # means 149\n",
    "\n",
    "    # th_lowEffect = 30.645161290322577 # means 430\n",
    "    # th_effective = 69.35483870967742 # means 190\n",
    "    th_lowEffect = 27 # means 399\n",
    "    th_effective = 73 # means 149\n",
    "    #n_sample = 124\n",
    "    #n_sample_effective = [38, 34, 40, 35, 43]\n",
    "    #n_sample_lowEffect = [n_sample - x for x in n_sample_effective]\n",
    "    #th_effective = [1 - x / n_sample for x in n_sample_effective]\n",
    "    #th_lowEffect = [1 - x / n_sample for x in n_sample_lowEffect]\n",
    "    \n",
    "    if n == 1:\n",
    "        file_name = 'config_g1.csv'\n",
    "    elif n == 2:\n",
    "        file_name = 'config_g2.csv'\n",
    "    else:\n",
    "        file_name = 'config_g3.csv'\n",
    "    return file_name, n, th_lowEffect, th_effective\n",
    "\n",
    "\n",
    "# # Load Train data\n",
    "def load_dataset(path, name):\n",
    "    triple_data = open(path + name).read().strip()\n",
    "    data = np.array([triple.split('\\t') for triple in triple_data.split('\\n')])\n",
    "    tf_data = TriplesFactory.from_labeled_triples(triples=data)\n",
    "    return tf_data, triple_data\n",
    "\n",
    "\n",
    "def create_model(tf_training, tf_testing, embedding, n_epoch, path, fold):\n",
    "    results = pipeline(\n",
    "        training=tf_training,\n",
    "        testing=tf_testing,\n",
    "        model=embedding,  # 'TransE',  #'RotatE'\n",
    "        # stopper='early',\n",
    "        # stopper_kwargs=dict(frequency=5, patience=2, relative_delta=0.002),\n",
    "        training_loop='sLCWA',\n",
    "        negative_sampler='bernoulli',\n",
    "        negative_sampler_kwargs=dict(\n",
    "        filtered=True,\n",
    "        ),\n",
    "        # Training configuration\n",
    "        training_kwargs=dict(\n",
    "            num_epochs=n_epoch,\n",
    "            use_tqdm_batch=False,\n",
    "        ),\n",
    "        # Runtime configuration\n",
    "        random_seed=1235,\n",
    "        device='gpu',\n",
    "    )\n",
    "    model = results.model\n",
    "    results.save_to_directory(path + embedding + str(fold))\n",
    "    return model, results\n",
    "\n",
    "\n",
    "# # Predict links (Head prediction)\n",
    "def predict_heads(model, prop, obj, tf_testing):  # triples_factory=results.training\n",
    "    predicted_heads_df = predict.get_head_prediction_df(model, prop, obj, triples_factory=tf_testing)\n",
    "    return predicted_heads_df\n",
    "\n",
    "\n",
    "# Filter the prediction by the head 'treatment_drug:treatment'. We are not interested in predict another links\n",
    "def filter_prediction(predicted_heads_df, constraint):\n",
    "    predicted_heads_df = predicted_heads_df[predicted_heads_df.head_label.str.contains(constraint)]\n",
    "    return predicted_heads_df\n",
    "\n",
    "\n",
    "def save_statistics(path, line):\n",
    "    with open(path + 'results_threshold.csv', 'a') as file:\n",
    "        file.write(line)\n",
    "\n",
    "\n",
    "def get_config(config_file):\n",
    "    config = pd.read_csv(config_file, delimiter=\";\")  # 'config_G1.csv'\n",
    "    models = config.model.values[0].split(',')\n",
    "    epochs = config.epochs.values[0]\n",
    "    k = config.k_fold.values[0]\n",
    "    path = config.path.values[0]\n",
    "    graph_name = config.graph_name.values[0]\n",
    "    return models, epochs, k, path, graph_name\n",
    "\n",
    "\n",
    "def load_testset_classes(path, name):\n",
    "    r = pd.read_csv(path + name, delimiter='\\t', header=None)\n",
    "    r.columns = ['head_label', 'p', 'o']\n",
    "    r['o'] = r['o'].str.replace(' .', '')\n",
    "    r_tox = r.loc[r.o == 'ex:effective']\n",
    "    head_tox = list(r_tox.head_label)\n",
    "    r_eff = r.loc[r.o == 'ex:low_effect']\n",
    "    head_eff = list(r_eff.head_label)\n",
    "    return head_tox, head_eff\n",
    "\n",
    "\n",
    "def adding_testset(predicted_heads, head):\n",
    "    predicted_heads.loc[predicted_heads.head_label.isin(head), 'in_training'] = True\n",
    "\n",
    "    predicted_heads.reset_index(inplace=True)\n",
    "    predicted_heads.drop(columns=['index'], inplace=True)\n",
    "    return predicted_heads\n",
    "\n",
    "\n",
    "def get_threshold(predicted_heads, percentile):\n",
    "    score_values = predicted_heads.score.values\n",
    "    threshold = np.percentile(score_values, percentile)\n",
    "    threshold_index = predicted_heads.loc[predicted_heads.score > threshold].shape[0]\n",
    "    return threshold, threshold_index\n",
    "\n",
    "\n",
    "def get_inflection_point(score_values):\n",
    "    # standard deviation\n",
    "    stdev = statistics.stdev(score_values)\n",
    "    # smooth\n",
    "    smooth = gaussian_filter1d(score_values, stdev)\n",
    "    # compute second derivative\n",
    "    smooth_d2 = np.gradient(np.gradient(smooth))\n",
    "    # find switching points\n",
    "    infls = np.where(np.diff(np.sign(smooth_d2)))[0]\n",
    "    if len(infls) == 1:\n",
    "        return infls[0]\n",
    "    if len(infls) == 0:\n",
    "        return len(score_values)\n",
    "    # middle inflection point\n",
    "    m_infls = infls[math.ceil(len(infls) / 2)]\n",
    "    return m_infls\n",
    "\n",
    "\n",
    "def get_precision(predicted_heads, inflection_index):\n",
    "    tp_fp = predicted_heads.iloc[0:inflection_index + 1]\n",
    "    tp = tp_fp.loc[tp_fp.in_training == True].shape[0]\n",
    "    prec = tp / tp_fp.shape[0]\n",
    "    return prec, tp\n",
    "\n",
    "\n",
    "def get_recall(predicted_heads, tp):\n",
    "    tp_fn = predicted_heads.loc[predicted_heads.in_training == True].shape[0]\n",
    "    rec = tp / tp_fn\n",
    "    return rec\n",
    "\n",
    "\n",
    "def get_f_measure(precision, recall):\n",
    "    f_measure = 2 * (precision * recall) / (precision + recall)\n",
    "    return f_measure\n",
    "\n",
    "\n",
    "def reset_index(predicted_heads):\n",
    "    predicted_heads.reset_index(inplace=True)\n",
    "    predicted_heads.drop(columns=['index'], inplace=True)\n",
    "    return predicted_heads\n",
    "\n",
    "\n",
    "def main(*args):\n",
    "    file_name, n, th_dec_eff, th_eff = select_graph(int(args[0]))\n",
    "    models, epochs, k, path, graph_name = get_config(file_name)\n",
    "    #models = ['TransE','TransH','RotatE','TransD', 'HolE', 'TransR', 'ERMLP', 'QuatE', 'RESCAL', 'SE', 'UM']\n",
    "    models = ['TransE','TransH','RotatE','TransD', 'HolE', 'TransR', 'ERMLP', 'QuatE', 'RESCAL', 'SE', 'UM']\n",
    "    for m in models:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f_measure = 0\n",
    "        for i in range(0, k):\n",
    "            tf_training, triple_train = load_dataset(path, 'train_' + str(i + 1) + '.ttl')\n",
    "            tf_testing, triple_test = load_dataset(path, 'test_' + str(i + 1) + '.ttl')\n",
    "            #model, results = create_model(tf_training, tf_testing, m, epochs, path, i + 1)\n",
    "            model = torch.load(path + m + str(i + 1) + '/trained_model.pkl', map_location='cpu') # , map_location='cpu'\n",
    "            predicted_heads_eff = predict_heads(model, 'ex:belong_to', 'ex:effective', tf_training)\n",
    "            predicted_heads_dec_eff = predict_heads(model, 'ex:belong_to', 'ex:low_effect',tf_training)\n",
    "\n",
    "            \n",
    "            predicted_heads_eff = filter_prediction(predicted_heads_eff, '<http://example/Treatment/treatment')\n",
    "            predicted_heads_dec_eff = filter_prediction(predicted_heads_dec_eff, '<http://example/Treatment/treatment')\n",
    "\n",
    "            head_eff, head_dec_eff = load_testset_classes(path, 'test_' + str(i + 1) + '.ttl')  # graph_name\n",
    "            predicted_heads_eff = adding_testset(predicted_heads_eff, head_eff)\n",
    "            predicted_heads_dec_eff = adding_testset(predicted_heads_dec_eff, head_dec_eff)\n",
    "\n",
    "            #inflection_index = get_inflection_point(predicted_heads_tox.score.values)\n",
    "            threshold, threshold_index = get_threshold(predicted_heads_eff, th_eff)\n",
    "            print(threshold_index)\n",
    "            precision_eff, tp = get_precision(predicted_heads_eff, threshold_index)\n",
    "            recall_eff = get_recall(predicted_heads_eff, tp)\n",
    "            f_measure_eff = get_f_measure(precision_eff, recall_eff)\n",
    "            print(precision_eff, recall_eff, f_measure_eff, tp)\n",
    "\n",
    "            #inflection_index = get_inflection_point(predicted_heads_eff.score.values)\n",
    "            threshold, threshold_index = get_threshold(predicted_heads_dec_eff, th_dec_eff)\n",
    "            precision_dec_eff, tp = get_precision(predicted_heads_dec_eff, threshold_index)\n",
    "            recall_dec_eff = get_recall(predicted_heads_dec_eff, tp)\n",
    "            f_measure_dec_eff = get_f_measure(precision_dec_eff, recall_dec_eff)\n",
    "            print(precision_dec_eff, recall_dec_eff, f_measure_dec_eff, tp)\n",
    "\n",
    "            precision += (precision_eff + precision_dec_eff) / 2\n",
    "            recall += (recall_eff + recall_dec_eff) / 2\n",
    "            f_measure += (f_measure_eff + f_measure_dec_eff) / 2\n",
    "            break\n",
    "            \n",
    "\n",
    "        avg_precision = precision / k\n",
    "        avg_recall = recall / k\n",
    "        avg_f_measure = f_measure / k\n",
    "        line = m + ';' + str(avg_precision) + ';' + str(avg_recall) + ';' + str(avg_f_measure) + '\\n'\n",
    "        #save_statistics(path, line)\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f0c0e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "0.2684563758389262 0.2684563758389262 0.2684563758389262 40\n",
      "0.71571072319202 0.7192982456140351 0.7175 287\n",
      "TransE;0.09841670990309462;0.09877546214529613;0.09859563758389263\n",
      "\n",
      "148\n",
      "0.30201342281879195 0.30201342281879195 0.30201342281879195 45\n",
      "0.6982543640897756 0.7017543859649122 0.7 280\n",
      "TransH;0.10002677869085677;0.10037678087837043;0.10020134228187919\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rivasa\\AppData\\Local\\Temp/ipykernel_19760/2602445860.py:101: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  r['o'] = r['o'].str.replace(' .', '')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RotatE' object has no attribute 'relation_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19760/3430799317.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19760/2602445860.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;31m#model, results = create_model(tf_training, tf_testing, m, epochs, path, i + 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/trained_model.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# , map_location='cpu'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m             \u001b[0mpredicted_heads_eff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ex:belong_to'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ex:effective'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[0mpredicted_heads_dec_eff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ex:belong_to'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ex:low_effect'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19760/2602445860.py\u001b[0m in \u001b[0;36mpredict_heads\u001b[1;34m(model, prop, obj, tf_testing)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;31m# # Predict links (Head prediction)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_testing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# triples_factory=results.training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mpredicted_heads_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_head_prediction_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtriples_factory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf_testing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpredicted_heads_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pykeen\\models\\predict.py\u001b[0m in \u001b[0;36mget_head_prediction_df\u001b[1;34m(model, relation_label, tail_label, triples_factory, add_novelties, remove_known, testing, mode)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mrelation_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtriples_factory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelation_to_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrelation_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mrt_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrelation_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtail_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrt_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     rv = pd.DataFrame(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pykeen\\models\\base.py\u001b[0m in \u001b[0;36mpredict_h\u001b[1;34m(self, rt_batch, slice_size, mode)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_h_inverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrt_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrt_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrt_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_with_sigmoid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pykeen\\models\\unimodal\\rotate.py\u001b[0m in \u001b[0;36mscore_h\u001b[1;34m(self, rt_batch, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscore_h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrt_batch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: D102\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;31m# Get embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelation_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrt_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal_embedding_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentity_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrt_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal_embedding_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m   1186\u001b[0m             type(self).__name__, name))\n\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RotatE' object has no attribute 'relation_embeddings'"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7756a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4420d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16085cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
